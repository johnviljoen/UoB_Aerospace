# Model Predictive Control

> Links: [[Aerospace Index]]

## Terminology

$$x_{k+1} = A x_k + B u_k$$

Where $x_k$ and $u_k$ are the model state and tinput vectors at the $k$th sampling instant. Given a predicted input sequence, the corresponding sequence of state predictions is generated by simulating the model forward over the prediction horizon, of say $N$ sampling intervals. For notational convenience, these predicted sequences are often stacked into vectors $\pmb{u}$, $\pmb{x}$ defined by:

$$\pmb{u}_k = \begin{bmatrix} u_{0|k} \\ u_{1|k} \\ \vdots \\ u_{N-1|k} \end{bmatrix}, \quad \pmb{x}_k = \begin{bmatrix} x_{0|k} \\ x_{1|k} \\ \vdots \\ x_{N|k} \end{bmatrix}$$

Here $u_{i|k}$ and $x_{i|k}$ denote input and state vectors at time $k+i$ that are predicted at time $k$ (i.e. predictions of their values $i$ steps ahead), and $x_{i|k}$ is goverened by the prediction model:

$$x_{i+1|k} = Ax_{i|k} + Bu_{i|k}, \quad i = 0,1,...$$

with initial condition (at the start of the prediction horizon) defined by

$$x_{0|k} = x_k$$

## Optimization

The predictive control feedback law is computed by minimizing a predicted performance cost, which is defined in terms of the predicted sequences $\pmb{u}$, $\pmb{x}$. This course is mainly concerned with the case of quadratic cost, for which the predicted cost has a general form:

$$J(x_k,\pmb{u}_k)= \Sigma_{i=0}^{N} \left( ||x_{i|k}||_{Q}^2 + ||u_{i|k}||_{R}^2 \right)$$

where $||x_{i|k}||_{Q}^2 = x^TQx$ and $Q, R$ are positive definite matrices ($Q$ may be positive semi definite). The optimal control sequence for the problem of minimizing the predicted cost is denoted $\pmb{u}_{k}^*$, and the optimal value of the cost is $J^*(x_k) = J(x_k, \pmb{u}_k^*)$, which is often written as $J_k^*$ for simplicity:

$$\pmb{u}_k^*(x_k) = \text{arg}\text{ min}_{\pmb{u}_k} J(x_k, \pmb{u}_k)$$

$$J_k^* = J^*(x_k) = J(x_k,\pmb{u}_k^*) = \text{min}_{\pmb{u}_k}J(x_k, \pmb{u}_k)$$

## Receding Horizon Implementation

## [[F16 Implementation]]

